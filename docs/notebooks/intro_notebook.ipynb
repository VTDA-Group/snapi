{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "textblock1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# SNAPI Demo\n",
    "This notebook showcases very basic functionality of SNAPI, including querying databases, saving/loading files and manipulating Transient objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5d6d7",
   "metadata": {},
   "source": [
    "## (1) Creating a Transient object for 2023ixf.\n",
    "Here, we will create a mostly empty Transient object for 2023ixf. We will add information through queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "codeblock1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapi import Transient\n",
    "\n",
    "ixf_transient = Transient(iid=\"2023ixf\")\n",
    "print(ixf_transient.id)\n",
    "print(ixf_transient.coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textblock2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "Next, we'll call TNS, ALeRCE, and ANTARES to add information based on the IAU name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "codeblock2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapi.query_agents import TNSQueryAgent, ALeRCEQueryAgent, ANTARESQueryAgent\n",
    "\n",
    "tns_query_agent = TNSQueryAgent()\n",
    "alerce_query_agent = ALeRCEQueryAgent()\n",
    "antares_query_agent = ANTARESQueryAgent()\n",
    "\n",
    "for agent in [tns_query_agent, alerce_query_agent, antares_query_agent]:\n",
    "    query_results, _ = agent.query_transient(ixf_transient)\n",
    "    for query_result in query_results:\n",
    "        ixf_transient.ingest_query_info(query_result.to_dict())\n",
    "    print(ixf_transient.internal_names)\n",
    "    print(len(ixf_transient.photometry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "codeblock3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all unique filters\n",
    "print(len(ixf_transient.photometry))\n",
    "for lc in ixf_transient.photometry.light_curves:\n",
    "    print(lc.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9be410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all extracted information\n",
    "print(ixf_transient.coordinates)\n",
    "print(ixf_transient.redshift)\n",
    "print(ixf_transient.spec_class)  # TODO: add spec class extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26dc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all photometry\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from snapi import Formatter\n",
    "\n",
    "formatter = Formatter()\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ixf_transient.photometry.plot(ax, formatter=formatter)\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ab3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also plot in flux space\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ixf_transient.photometry.plot(ax, mags=False)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "formatter.make_plot_pretty(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e43ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapi import Formatter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# can also plot each LC individually\n",
    "formatter = Formatter()\n",
    "fig, axes = plt.subplots(4, 2, figsize=(10, 14))\n",
    "for i, lc in enumerate(ixf_transient.photometry.light_curves):\n",
    "    ax = axes.flatten()[i]\n",
    "    lc.plot(ax, formatter)\n",
    "    ax.legend(loc=\"best\")\n",
    "    # formatter.make_plot_pretty(ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38114b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save this object for later\n",
    "ixf_transient.save(filename=\"data/ixf_transient.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274125c8",
   "metadata": {},
   "source": [
    "## Example 2: Querying by RA/dec\n",
    "Whereas the previous example queries by IAU name, we instead consider an example where we query from RA/dec coordinates. For this example, we use a dataset of DECAM DDF \"likely-real\" candidates: https://arxiv.org/abs/2211.09202 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DECAM data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "decam_fn = \"data/candidates.dat\"\n",
    "decam_df = pd.read_table(\n",
    "    decam_fn,\n",
    "    sep=r\"\\s+\",\n",
    "    comment=\"#\",\n",
    "    names=[\"field\", \"id\", \"ra\", \"dec\", \"n_obs\", \"mean_rb\"],\n",
    "    usecols=np.arange(6),\n",
    ")\n",
    "print(decam_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee03d8",
   "metadata": {},
   "source": [
    "There are two sets of fields in the DECAM deep-drilling fields: 3 fields that overlap with COSMOS (declination ~1-4 degrees), and 2 fields at lower declination (-45 -> -42 deg). Let's display them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db672733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# plot COSMOS ra/dec distribution\n",
    "cosmos_ddf = decam_df[decam_df[\"field\"] == \"COSMOS\"]\n",
    "l = ax[0].scatter(\n",
    "    cosmos_ddf[\"ra\"], cosmos_ddf[\"dec\"], c=cosmos_ddf[\"mean_rb\"], cmap=\"viridis\", vmax=1.0, s=10\n",
    ")\n",
    "ax[0].set_title(\"COSMOS fields\")\n",
    "\n",
    "# plot non-COSMOS fields\n",
    "non_cosmos_ddf = decam_df[decam_df[\"field\"] != \"COSMOS\"]\n",
    "l2 = ax[1].scatter(\n",
    "    non_cosmos_ddf[\"ra\"], non_cosmos_ddf[\"dec\"], c=non_cosmos_ddf[\"mean_rb\"], cmap=\"viridis\", vmax=1.0, s=10\n",
    ")\n",
    "ax[1].set_title(\"Non-COSMOS fields\")\n",
    "fig.colorbar(label=\"Mean real-bogus score\", mappable=l2)\n",
    "\n",
    "ax[0].set_xlabel(\"RA\")\n",
    "ax[1].set_xlabel(\"RA\")\n",
    "ax[0].set_ylabel(\"Dec\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1d7d2",
   "metadata": {},
   "source": [
    "As we can see, all events in this dataset have a mean real-bogus score above 0.4, which is the \"probably-real\" threshhold according to the paper, so we keep all events for cross-matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now colorbar by number of observations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# plot COSMOS ra/dec distribution\n",
    "cosmos_ddf = decam_df[decam_df[\"field\"] == \"COSMOS\"]\n",
    "l = ax[0].scatter(cosmos_ddf[\"ra\"], cosmos_ddf[\"dec\"], c=cosmos_ddf[\"n_obs\"], cmap=\"viridis\", vmax=100, s=10)\n",
    "ax[0].set_title(\"COSMOS fields\")\n",
    "\n",
    "# plot non-COSMOS fields\n",
    "non_cosmos_ddf = decam_df[decam_df[\"field\"] != \"COSMOS\"]\n",
    "l2 = ax[1].scatter(\n",
    "    non_cosmos_ddf[\"ra\"], non_cosmos_ddf[\"dec\"], c=non_cosmos_ddf[\"n_obs\"], cmap=\"viridis\", vmax=100, s=10\n",
    ")\n",
    "ax[1].set_title(\"Non-COSMOS fields\")\n",
    "fig.colorbar(label=\"Number of observations\", mappable=l2)\n",
    "\n",
    "ax[0].set_xlabel(\"RA\")\n",
    "ax[1].set_xlabel(\"RA\")\n",
    "ax[0].set_ylabel(\"Dec\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181b7343",
   "metadata": {},
   "source": [
    "Many events (those in yellow) have over 100 observations; they are probably AGN or very long-duration TDEs/SNe.\n",
    "\n",
    "Because northern sky telescopes like ZTF and Pan-STARRS have a minimum declination > ~-30 degrees, we expect potential cross-matches in TNS with only the COSMOS fields. Let's use SNAPI to make this cross-matching simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from snapi import Transient\n",
    "from snapi.query_agents import TNSQueryAgent\n",
    "\n",
    "tns_query_agent = TNSQueryAgent()\n",
    "cross_matched_transients = set()\n",
    "\n",
    "\n",
    "for i, row in decam_df.iterrows():\n",
    "    if i % 500 == 0:\n",
    "        print(f\"Processing transient {i}/{len(decam_df)}\")\n",
    "    decam_transient = Transient(\n",
    "        iid=row[\"id\"],\n",
    "        ra=row[\"ra\"] * u.deg,  # pylint: disable=no-member\n",
    "        dec=row[\"dec\"] * u.deg,  # pylint: disable=no-member\n",
    "    )\n",
    "\n",
    "    # query TNS\n",
    "    query_results, _ = tns_query_agent.query_transient(decam_transient, local=True)\n",
    "    for query_result in query_results:\n",
    "        decam_transient.ingest_query_info(query_result.to_dict())\n",
    "\n",
    "    # check if IAU name found\n",
    "    if decam_transient.internal_names:  # check if non-empty\n",
    "        print(f\"Matched {row['id']} with TNS object {decam_transient.spec_class} {decam_transient.id}\")\n",
    "        cross_matched_transients.add(decam_transient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100083a",
   "metadata": {},
   "source": [
    "We see we've successfully crossmatched a handful of DDF events with TNS! Let's save the Transient objects so we don't have to rerun that loop every time. Luckily, SNAPI has extremely straightforward save/load functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f255ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matching transients\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "for transient in cross_matched_transients:\n",
    "    transient.save(f\"data/ddf_transient_{transient.id}.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25f658",
   "metadata": {},
   "source": [
    "Now that we've reduced the dataset down to a small number, let's run a full query loop on each event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222912c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from snapi.query_agents import TNSQueryAgent, ALeRCEQueryAgent, ANTARESQueryAgent\n",
    "from snapi import Transient, Formatter\n",
    "\n",
    "tns_agent = TNSQueryAgent()\n",
    "alerce_agent = ALeRCEQueryAgent()\n",
    "antares_agent = ANTARESQueryAgent()\n",
    "formatter = Formatter()\n",
    "\n",
    "# ensure we can load the transients\n",
    "for f in glob.glob(\"data/ddf_transient_*.hdf5\"):\n",
    "    transient = Transient.load(f)\n",
    "\n",
    "    # small internal names fix\n",
    "    internal_names = set(transient.internal_names)\n",
    "    if \"nan\" in transient.internal_names:\n",
    "        internal_names.remove(\"nan\")\n",
    "    transient.internal_names = internal_names\n",
    "\n",
    "    for agent in [tns_agent, antares_agent]:\n",
    "        query_results, _ = agent.query_transient(transient)\n",
    "        for query_result in query_results:\n",
    "            transient.ingest_query_info(query_result.to_dict())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    transient.photometry.plot(ax)\n",
    "    ax.set_title(f\"{transient.id} ({\", \".join(transient.internal_names)})\")\n",
    "    formatter.make_plot_pretty(ax)\n",
    "    formatter.add_legend(ax, ncols=2)\n",
    "    plt.show()\n",
    "\n",
    "    # now re-save\n",
    "    transient.save(f\"data/ddf_transient2_{transient.id}.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba60429",
   "metadata": {},
   "source": [
    "2019tzk looks like an AGN, and has significant ZTF data. Let's overlay our DECAM data by adding it to the Transient object and re-plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from astropy.timeseries import TimeSeries\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import LightCurve, Filter, Formatter, Transient\n",
    "import os\n",
    "\n",
    "transient_2019tzk = Transient.load(\"data/ddf_transient2_2019tzk.hdf5\")\n",
    "formatter = Formatter()\n",
    "\n",
    "observations_df = pd.read_csv(\n",
    "    \"data/DC21fyx.csv\",\n",
    "    usecols=[4, 5, 6, 7, 8],\n",
    "    header=0,\n",
    ")\n",
    "print(observations_df.head())\n",
    "\n",
    "for band in np.unique(observations_df[\"filter\"]):\n",
    "    band_df = observations_df[observations_df[\"filter\"] == band]\n",
    "    filt = Filter(\n",
    "        instrument=\"DECam\",\n",
    "        band=band,\n",
    "        center=np.nan * u.AA,\n",
    "    )\n",
    "    time_mjds = Time(band_df[\"meanmjd\"].values, format=\"mjd\")\n",
    "    lc = LightCurve(\n",
    "        times=time_mjds,\n",
    "        fluxes=band_df[\"flux\"].values,\n",
    "        flux_errs=band_df[\"fluxerr\"].values,\n",
    "        zpts=band_df[\"magzp\"].values,\n",
    "        filt=filt,\n",
    "    )\n",
    "    transient_2019tzk.photometry.add_lightcurve(lc)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "transient_2019tzk.photometry.plot(ax)\n",
    "ax.set_title(\"2019tzk (with DECam data)\")\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total observations: {len(transient_2019tzk.photometry.time_series)}\")\n",
    "\n",
    "\n",
    "transient_2019tzk_path = os.path.abspath(\"data/ddf_transientdecam_2019tzk.hdf5\")\n",
    "transient_2019tzk.save(transient_2019tzk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b827f6a",
   "metadata": {},
   "source": [
    "We see here that the DECam and ZTF data align very well, capturing the same stochastic behavior of the AGN. However, we note that above, there were TWO DECam events that mapped to 2019tzk, the other being DC21crhk. Let's add that data in as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from astropy.timeseries import TimeSeries\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import LightCurve, Filter, Formatter, Transient\n",
    "import os\n",
    "\n",
    "transient_2019tzk = Transient.load(\"data/ddf_transientdecam_2019tzk.hdf5\")\n",
    "formatter = Formatter()\n",
    "\n",
    "observations_df = pd.read_table(\n",
    "    \"data/DC21crhk.csv\",\n",
    "    usecols=[5, 6, 7, 8],\n",
    "    names=[\"meanmjd\", \"filter\", \"mag\", \"magerr\"],\n",
    "    sep=r\"\\s+\",\n",
    ")\n",
    "\n",
    "for band in np.unique(observations_df[\"filter\"]):\n",
    "    band_df = observations_df[observations_df[\"filter\"] == band]\n",
    "    filt = Filter(\n",
    "        instrument=\"DECam\",\n",
    "        band=band,\n",
    "        center=np.nan * u.AA,\n",
    "    )\n",
    "    time_mjds = Time(band_df[\"meanmjd\"].values, format=\"mjd\")\n",
    "    lc = LightCurve(times=time_mjds, mags=band_df[\"mag\"].values, mag_errs=band_df[\"magerr\"].values, filt=filt)\n",
    "    transient_2019tzk.photometry.add_lightcurve(lc)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "transient_2019tzk.photometry.plot(ax)\n",
    "ax.set_title(\"2019tzk (with more DECam data)\")\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total observations: {len(transient_2019tzk.photometry.time_series)}\")\n",
    "transient_2019tzk_path = os.path.abspath(\"data/ddf_transientdecam_2019tzk.hdf5\")\n",
    "transient_2019tzk.save(transient_2019tzk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f4d61",
   "metadata": {},
   "source": [
    "Only 11 observations were added, so not much difference is noted!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8b3a7",
   "metadata": {},
   "source": [
    "## Example 3: Modifying light curves for ML applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10615c",
   "metadata": {},
   "source": [
    "After colating all information about a transient event, we may still need to restructure that information so it can be used for machine learning applications. For this tutorial, we will focus on formatting light curves for RNNs and convolutional neural networks, as well as light curve augmentation for better training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f63490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this example, we'll be using ZTF photometry from 2023ixf.\n",
    "from snapi import Transient\n",
    "import matplotlib.pyplot as plt\n",
    "from snapi import Formatter\n",
    "\n",
    "formatter = Formatter()\n",
    "ixf_transient = Transient.load(\"data/ixf_transient.hdf5\")\n",
    "ixf_photometry = ixf_transient.photometry\n",
    "ztf_photometry = ixf_photometry.filter({\"ZTF_g\", \"ZTF_r\"})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ztf_photometry.plot(ax, formatter=formatter)\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs = ztf_photometry.light_curves  # returns a copy of _light_curves\n",
    "for lc in lcs:\n",
    "    lc.phase()\n",
    "ztf_photometry = Photometry(lcs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ztf_photometry.plot(ax, formatter=formatter)\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a5b9b3",
   "metadata": {},
   "source": [
    "REST OF DEMO:\n",
    "Basic functionality:\n",
    "- retrieve detections vs non-detections (maybe return LC not time series)\n",
    "- add_observation and remove_observation\n",
    "- add LC and remove LC\n",
    "- filter photometry by filter\n",
    "\n",
    "ML functionality:\n",
    "- phase photometry (implement peak and phase functions)\n",
    "- show photometry tiling\n",
    "- show photometry dense_lc\n",
    "- show photometry CNN images\n",
    "- show LC subsampling\n",
    "- show LC merge_close_times (use AGN light curve)\n",
    "- show LC resampling\n",
    "- show LC padding\n",
    "- show LC feature extraction (Kostya's package)\n",
    "\n",
    "Mention host galaxy + spectroscopy in future\n",
    "MAKE FIGURE OF CLASSES\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d0eff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
